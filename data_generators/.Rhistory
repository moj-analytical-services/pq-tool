clusterNum <- cutree(hier,h=similarityThreshold)
#number of clusters with more than one occupant
clustSizes <- sapply(seq(max(clusterNum)),function(x)length(which(clusterNum==x)))
names(clustSizes) <- seq(max(clusterNum))
numberOfGroups <- length(clustSizes[which(clustSizes>1)])
#nonSingleClusters
GroupDF <- data_frame(answer=nonEmptyAnswers,
YN=nonEmptyYN,
profession=nonEmptyProfs,
profession2=nonEmptyProf2s,
cluster=clusterNum,
clusterSize=clustSizes[clusterNum])
bigClusters <- GroupDF %>%
filter(clusterSize>1) %>%
mutate(group = dense_rank(cluster)) %>%
select(YN, answer, profession, group) %>%
arrange(group)
##Output
cat("There were ",nrow(GroupDF)," text responses.","\n","\n")
cat("###Single words","\n")
print(
mostCommonWordsYes %>% ggplot(aes(x=reorder(word,n),n/total)) + geom_col(fill="#66c2a5") + labs(x=NULL,y="relative frequency") + coord_flip() + ggtitle(paste0("Most common words associated with Yes answers, question ",i)))
print(
mostCommonWordsNo %>% ggplot(aes(x=reorder(word,n),n/total)) + geom_col(fill="#fc8d62") + labs(x=NULL,y="relative frequency") + coord_flip() + ggtitle(paste0("Most common words associated with No answers, question ",i)))
cat("\n","\n")
cat("###Word pairs","\n","\n")
print(
mostCommonBigramsYes %>% ggplot(aes(x=reorder(phrase,n),n/total)) + geom_col(fill="#66c2a5") + labs(x=NULL,y="relative frequency") + coord_flip() + ggtitle(paste0("Most common bigrams associated with Yes answers, question ",i)))
print(
mostCommonBigramsNo %>% ggplot(aes(x=reorder(phrase,n),n/total)) + geom_col(fill="#fc8d62") + labs(x=NULL,y="relative frequency") + coord_flip() + ggtitle(paste0("Most common bigrams associated with No answers, question ",i)))
cat("\n","\n")
#LSA
cat("###Similar answers","\n")
cat("We have automatically detected ",
numberOfGroups,
" groups with responses that are very similar to one another, accounting for ",
nrow(bigClusters),
" responses out of a total of",
nrow(GroupDF),
". They are printed below.")
for(i in 1:numberOfGroups){
cat("\n","\n")
cat("####Group ",i,"\n")
#answerGroup <- paste("Group",i)
bigClusters %>%
filter(group==i) %>%
mutate(answer2=swapOutUnicode(answer)) %>%
select(YN,answer2,profession) %>%
dust() %>%
sprinkle_colnames(YN="Yes or No", profession="Profession", answer2="Answer") %>%
sprinkle_print_method("html") %>%
sprinkle(border=c("top","bottom"),border_color="gray") %>%
sprinkle(cols=1,width=50) %>%
sprinkle(cols=2,width=400) %>%
sprinkle(cols=3,width=80,halign="right") %>%
sprinkle(cols=2,halign="center",part="head") %>%
sprinkle(cols=3,halign="right",part="head") %>%
print() %>%
cat()
}
cat("\n","\n")
}
View(Qi)
Qi %>% filter(YN=="Yes") %>% nrow()
Qi %>% filter(YN=="No") %>% nrow()
Qi %>% filter(YN=="Not Answered") %>% nrow()
Qi$YN %>% unique()
nrow(Qi)
answers = c(yesAnswers)
Qtitle <- sapply(1:numberOfQuestions,Qtitle)
#FUNCTIONS
#this replaces a lot of the unicode codes with their symbols for output
swapOutUnicode <- function(stringInput){
stringInput <- stringInput %>% gsub("<a3>","£",.) %>%
gsub("<d0>","-",.) %>%
gsub("<d2>","'",.) %>%
gsub("<d3>","'",.) %>%
gsub("<d4>","'",.) %>%
gsub("<d5>","'",.)
return(stringInput)
}
#Given a question number, this takes the raw data and creates a data frame
#containing the ID of the respondent, whether they answered yes or no,
#and the text of their answer. It forms the basis of the analysis as it
#provides regularised objects to work on.
Qdf <- function(N){
return(
data_frame(
ID = rawdata[,1],
Qnumber = rep(N,length(rawdata[,1])),
Profession = rawdata[,6],
Profession2 = rawdata[,7],
YN = rawdata[,2*N+9],
answer=rawdata[,2*N+10] %>%
iconv(to='UTF-8-MAC', sub='byte') %>%
sapply(swapOutUnicode),
stemmedAnswer=rawdata[,2*N+10] %>%
iconv(to='UTF-8-MAC', sub='byte') %>%
sapply(swapOutUnicode) %>%
removePunctuation() %>%
stripWhitespace() %>%
tolower() %>%
stemDocument(),
stringsAsFactors = F
)
)
}
#this function gets the question itself from the raw data
Qtitle <- function(Qnum){
return(str_replace(names(rawdata)[2*Qnum+9]," - Please select radio button",""))
}
#FREQUENCY COUNTING
#This finds the x most common n-grams in a given Qdf dataframe, where
#n=1 or 2.
#In English: it will give you the most common words or bigrams.
findCommonNGrams <- function(Qdf,n=1,x=20,YNresp="All"){
if(n==1){
#manipulate the data so that each word has its own row
tidy_Qdf<- Qdf %>% unnest_tokens(word,answer,to_lower=TRUE)
#remove stopwords
clean_Qdf <- tidy_Qdf %>% anti_join(stop_words)
#count the occurrences of each word, sort by the number of occurrences, and take the top x
top_x <- clean_Qdf %>% count(word,YN,sort=TRUE)
#find total number of words for each Yes/No answer type
wordsPerYN <- top_x %>% group_by(YN) %>% summarise(total = sum(n))
#join this information in
top_x <- left_join(top_x,wordsPerYN)
#If user has specified a yes/no answer type, include only these rows
if(YNresp!="All"){
top_x <- filter(top_x,YN==YNresp)
}
#include only the first x rows
top_x <- top_x[1:x,]
}
else if(n==2){
#manipulate the data so that each bigram has its own row
tidy_Qdf<- Qdf %>% unnest_tokens(bigram,answer,to_lower=TRUE,token="ngrams",n=2)
#separate bigrams into individual words
bigrams_separated <- tidy_Qdf %>% separate(bigram, c("word1", "word2"), sep = " ")
#remove cases where one of the words is a stopword
bigrams_filtered <- bigrams_separated %>%
filter(!word1 %in% stop_words$word) %>%
filter(!word2 %in% stop_words$word)
#count the occurrences of word pairs, sort by the number of occurrences
top_x <- bigrams_filtered %>% count(word1, word2, YN, sort = TRUE)
phrasesPerYN <- top_x %>% group_by(YN) %>% summarise(total = sum(n))
top_x <- left_join(top_x,phrasesPerYN)
if(YNresp!="All"){
top_x <- filter(top_x,YN==YNresp)
}
#include only the first x rows
top_x <- top_x[1:x,]
#rejoin the words back into bigrams
top_x <- ungroup(top_x) %>%
mutate(phrase=paste(word1,word2)) %>%
select(phrase,YN,n,total)
}
Qnumber<-rep(Qdf$Qnumber[1],x)
return(cbind(as.data.frame(top_x),Qnumber))
}
#Function to output the answers given a question number
freqSection <- function(qNum){
Qi <- Qdf(qNum)
mostCommonWordsYes <- findCommonNGrams(Qi,YNresp="Yes")
mostCommonWordsNo <- findCommonNGrams(Qi,YNresp="No")
mostCommonBigramsYes <- findCommonNGrams(Qi,n=2,YNresp="Yes")
mostCommonBigramsNo <- findCommonNGrams(Qi,2,YNresp="No")
mostCommonWordsYes %>% ggplot(aes(x=reorder(word,n),n/total)) + geom_col(fill="#66c2a5") + labs(x=NULL,y="relative frequency") + coord_flip() + ggtitle("Most common words associated with Yes answers") %>% print()
mostCommonWordsNo %>% ggplot(aes(x=reorder(word,n),n/total)) + geom_col(fill="#fc8d62") + labs(x=NULL,y="relative frequency") + coord_flip() + ggtitle("Most common words associated with No answers") %>% print()
mostCommonBigramsYes %>% ggplot(aes(x=reorder(phrase,n),n/total)) + geom_col(fill="#66c2a5") + labs(x=NULL,y="relative frequency") + coord_flip() + ggtitle("Most common bigrams associated with Yes answers") %>% print()
mostCommonBigramsNo %>% ggplot(aes(x=reorder(phrase,n),n/total)) + geom_col(fill="#fc8d62") + labs(x=NULL,y="relative frequency") + coord_flip() + ggtitle("Most common bigrams associated with No answers") %>% print()
}
#LSA FUNCTION, FOR GROUPING ANSWERS BASED ON WORD CONTENT
#We do everything based around the R Corpus object
#stopword list - we use SMART
stopwordList <- stopwords("SMART")
stopwordList <- stopwordList[-which(stopwordList=="sensible")]
#this cleans corpus
cleanCorpus <- function(corp,removeStopWords=TRUE) {
toSpace <- content_transformer(function(x, pattern) { return (gsub(pattern, ' ', x))})
corp <-corp %>%
tm_map(FUN=content_transformer(function(x) iconv(x, to='latin1', sub='byte'))) %>%
tm_map(toSpace, '-') %>%
tm_map(toSpace, '’') %>%
tm_map(toSpace, '‘') %>%
tm_map(toSpace, '•') %>%
tm_map(toSpace, '”') %>%
tm_map(toSpace, '“') %>%
tm_map(content_transformer(tolower)) %>%
tm_map(removePunctuation) %>%
tm_map(stripWhitespace)
if(removeStopWords==TRUE){
corp <- tm_map(corp, function(x) removeWords(x,stopwordList))}
return(corp)
}
Qtitle <- sapply(1:numberOfQuestions,Qtitle)
for(i in 1:numberOfQuestions){
cat("###Question ",i,":","\n","\n")
cat("##",Qtitle[i],"\n","\n")
##Analysis
Qi <- Qdf(i)
#Number of Yes/No/Not answered responses
yesAnswers <- Qi %>% filter(YN=="Yes") %>% nrow()
noAnswers <- Qi %>% filter(YN=="No") %>% nrow()
notAnswered <- Qi %>% filter(YN=="Not Answered") %>% nrow()
#Frequency counting
mostCommonWordsYes <- findCommonNGrams(Qi,YNresp="Yes")
mostCommonWordsNo <- findCommonNGrams(Qi,YNresp="No")
mostCommonBigramsYes <- findCommonNGrams(Qi,n=2,YNresp="Yes")
mostCommonBigramsNo <- findCommonNGrams(Qi,n=2,YNresp="No")
#LSA
#make a corpus from question responses
corp <- Qi$answer %>% VectorSource() %>% Corpus() %>% cleanCorpus()
#stem the words in the corpus
stemmedCorpus <- corp %>% tm_map(stemDocument)
#make the tdm
TDM <- stemmedCorpus %>% TermDocumentMatrix(control = list(weighting = function(x) weightSMART(x, spec = "ntc")))
colTotals <- TDM %>% apply(2,sum)
TDM  <- TDM[,colTotals > 0]
LSA <- TDM %>% lsa(dims = dimcalc_raw())
nonEmptyAnswers <- Qi$answer[colTotals>0]
nonEmptyProfs <- Qi$Profession[colTotals>0]
nonEmptyProf2s <- Qi$Profession2[colTotals>0]
nonEmptyYN <- Qi$YN[colTotals>0]
#we get the positions of the documents in the manifold defined by the LSA
posns <- diag(LSA$sk) %*% t(LSA$dk)
cosDists <- 1-cosine(posns)
hier <- cosDists %>% as.dist() %>% hclust(method = "single")
clusterNum <- cutree(hier,h=similarityThreshold)
#number of clusters with more than one occupant
clustSizes <- sapply(seq(max(clusterNum)),function(x)length(which(clusterNum==x)))
names(clustSizes) <- seq(max(clusterNum))
numberOfGroups <- length(clustSizes[which(clustSizes>1)])
#nonSingleClusters
GroupDF <- data_frame(answer=nonEmptyAnswers,
YN=nonEmptyYN,
profession=nonEmptyProfs,
profession2=nonEmptyProf2s,
cluster=clusterNum,
clusterSize=clustSizes[clusterNum])
bigClusters <- GroupDF %>%
filter(clusterSize>1) %>%
mutate(group = dense_rank(cluster)) %>%
select(YN, answer, profession, group) %>%
arrange(group)
##Output
cat("There were ",
nrow(Qi),
" responses in total.",
"\n \n \n")
cat("* ",
yesAnswers,
" answered **Yes**",
"\n \n")
cat("* ",
noAnswers,
" answered **No**",
"\n \n")
cat("* ",
notAnswered,
" did not answer.",
"\n \n")
cat("There were ",
nrow(GroupDF),
"text responses.",
"\n \n")
cat("###Most common single words","\n")
print(
mostCommonWordsYes %>% ggplot(aes(x=reorder(word,n),n/total)) + geom_col(fill="#66c2a5") + labs(x=NULL,y="relative frequency") + coord_flip() + ggtitle(paste0("Most common words associated with Yes answers, question ",i)))
print(
mostCommonWordsNo %>% ggplot(aes(x=reorder(word,n),n/total)) + geom_col(fill="#fc8d62") + labs(x=NULL,y="relative frequency") + coord_flip() + ggtitle(paste0("Most common words associated with No answers, question ",i)))
cat("\n","\n")
cat("###Most common word pairs","\n","\n")
print(
mostCommonBigramsYes %>% ggplot(aes(x=reorder(phrase,n),n/total)) + geom_col(fill="#66c2a5") + labs(x=NULL,y="relative frequency") + coord_flip() + ggtitle(paste0("Most common word pairs associated with Yes answers, question ",i)))
print(
mostCommonBigramsNo %>% ggplot(aes(x=reorder(phrase,n),n/total)) + geom_col(fill="#fc8d62") + labs(x=NULL,y="relative frequency") + coord_flip() + ggtitle(paste0("Most common word pairs associated with No answers, question ",i)))
cat("\n","\n")
#LSA
cat("###Similar answers","\n")
cat("We have automatically detected ",
numberOfGroups,
" groups with responses that are very similar to one another, accounting for ",
nrow(bigClusters),
" responses out of a total of",
nrow(GroupDF),
". They are printed below.")
for(i in 1:numberOfGroups){
cat("\n","\n")
cat("####Group ",i,"\n")
#answerGroup <- paste("Group",i)
bigClusters %>%
filter(group==i) %>%
mutate(answer2=swapOutUnicode(answer)) %>%
select(YN,answer2,profession) %>%
dust() %>%
sprinkle_colnames(YN="Yes or No", profession="Profession", answer2="Answer") %>%
sprinkle_print_method("html") %>%
sprinkle(border=c("top","bottom"),border_color="gray") %>%
sprinkle(cols=1,width=50) %>%
sprinkle(cols=2,width=400) %>%
sprinkle(cols=3,width=80,halign="right") %>%
sprinkle(cols=2,halign="center",part="head") %>%
sprinkle(cols=3,halign="right",part="head") %>%
print() %>%
cat()
}
cat("\n","\n")
}
answers=c(yesAnswers,noAnswers)
answers
names(answers) <- c("Yes","No")
ggplot(aes(answers))
ggplot(answers)
ggplot(answers,aes(answers))
answerCounts=data_frame(label=c("Yes","No"),answers=c(yesAnswers,noAnswers))
rm(answers)
ggplot(answerCounts)
ggplot(answerCounts,aes(answers))
g<-ggplot(answerCounts,aes(answers))
g + geom_bar()
g+geom_bar(aes(weight=answers))
g+geom_bar(aes(fill=answers))
g<-ggplot(answerCounts)
g+geom_bar(aes(fill=answers))
answerCounts=data_frame(dummy=1,label=c("Yes","No"),answers=c(yesAnswers,noAnswers))
g<-ggplot(answerCounts,aes(dummy))
g+geom_bar(aes(fill=answers))
answerCounts=data_frame(dummy="answers",label=c("Yes","No"),answers=c(yesAnswers,noAnswers),total=c(yesAnswers+noAnswers))
g<-ggplot(answerCounts,aes(dummy))
g+geom_bar(aes(fill=answers))
g<-ggplot(answerCounts,aes(dummy))
g<-ggplot(answerCounts,aes(dummy))
g+geom_bar(aes(fill=answers,color=c("red","green")))
View(answerCounts)
g<-ggplot(answerCounts,aes(x=dummy,abswers/total))
g+geom_bar(aes(fill=answers,color=c("red","green")))
g<-ggplot(answerCounts,aes(x=dummy,answers/total))
g+geom_bar(aes(fill=answers,color=c("red","green")))
g<-ggplot(answerCounts,aes(x=dummy,answers/total))
g+geom_bar()
rep("Yes",yesAnswers)
answerCounts <- data.frame(value=1,answer=c(rep("Yes",yesAnswers),rep("No",noAnswers)))
View(answerCounts)
g<-ggplot(answerCounts,aes(answer))
g+geom_bar
g<-ggplot(answerCounts,aes(answer))
g
testPlot<-ggplot(answerCounts,aes(answer))
testPlot + geom_bar()
testPlot<-ggplot(answerCounts)
testPlot + geom_bar(fill=answer)
testPlot + geom_bar(aes(fill=answer))
testPlot + geom_bar(aes(value))
testPlot<-ggplot(answerCounts,aes(value))
testPlot + geom_bar(aes(fill=answer))
testPlot<-ggplot(answerCounts,aes(value))
answerCounts <- data.frame(value=1,answer=c(rep("Yes",yesAnswers),rep("No",noAnswers)),total=yesAnswers+noAnswers)
testPlot<-ggplot(answerCounts,aes(value))
testPlot + geom_bar(aes(fill=answer/total))
answerCounts <- data.frame(value=1,answer=c(rep("Yes",yesAnswers),rep("No",noAnswers)))
testPlot<-ggplot(answerCounts,aes(value))
testPlot + geom_bar(aes(fill=answer/total))
testPlot + geom_bar(aes(fill=answer))
testPlot + geom_bar(aes(fill=answer)) + coord_flip()
testPlot + geom_bar(aes(fill=answer)) + coord_flip() + geom_col(fill=c("#66c2a5","#fc8d62"))
testPlot + geom_bar(aes(fill=answer)) + coord_flip())
testPlot<-ggplot(answerCounts,aes(value))
testPlot + geom_bar(aes(fill=answer)) + coord_flip()
testPlot + geom_bar(aes(fill=answer)) + coord_flip() + scale_colour_manual(values = c("#66c2a5", "yellow"))
testPlot + geom_bar(aes(fill=answer)) + coord_flip() + scale_colour_manual(values = c("#66c2a5", "#fc8d62"))
testPlot + geom_bar(aes(fill=answer)) + coord_flip() + scale_colour_manual(values = c("#66c2a5", "#fc8d62")) + scale_color_fill()
testPlot + geom_bar(aes(fill=answer)) + coord_flip() + scale_colour_manual(values = c("#66c2a5", "#fc8d62")) + scale_colour_fill()
?scale_color_manual
testPlot + geom_bar(aes(fill=answer)) + coord_flip() + scale_colour_manual(values = c("#66c2a5", "#fc8d62"))
testPlot + geom_col(aes(fill=answer))
testPlot + geom_col(fill=answer)
testPlot + geom_bar(aes(fill=answer)) + coord_flip() + scale_colour_manual(values = c("#66c2a5", "#fc8d62"))
testPlot + geom_bar(aes(fill=answer)) + coord_flip() + scale_colour_manual(values = c("blue", "yellow"))
testPlot + geom_bar(aes(fill=answer,colour=c("#66c2a5", "#fc8d62"))) + coord_flip()
testPlot + geom_bar(aes(fill=answer,colour=c(rep("#66c2a5",yesAnswers),rep("#fc8d62",noAnswers)))) + coord_flip()
testPlot<-ggplot(answerCounts,aes(value))
answerCounts <- data.frame(value=1,answer=c(yesAnswers,noAnswers))
testPlot<-ggplot(answerCounts,aes(value))
testPlot + geom_col(aes(answer))
testPlot + geom_col(aes(x=value,y=answer))
testPlot + geom_col(aes(x=value,y=answer,fill=c("#66c2a5", "#fc8d62")))
testPlot + geom_col(aes(x=value,y=answer,fill=answer))
answerCounts <- data.frame(value=1,number=c(yesAnswers,noAnswers),answer=c("Yes","No"))
testPlot<-ggplot(answerCounts,aes(value))
testPlot + geom_col(aes(x=value,y=number,fill=answer))
?geom_col
testPlot + geom_col(aes(x=value,y=number,fill=answer,colour=c("#66c2a5", "#fc8d62")))
testPlot + geom_col(aes(x=value,y=number,group=answer,colour=c("#66c2a5", "#fc8d62")))
testPlot + geom_col(aes(x=value,y=number,group=answer,fill=c("#66c2a5", "#fc8d62")))
testPlot + geom_col(aes(x=value,y=number,group=answer,fill=c("red", "grey")))
testPlot + geom_col(aes(x=value,y=number,group=answer,fill=answer)) + scale_fill_manual(c("#66c2a5", "#fc8d62"))
testPlot + geom_col(aes(x=value,y=number,group=answer,fill=answer)) + scale_fill_manual(values=fill(c("#66c2a5", "#fc8d62")))
?scale_fill_manual
testPlot + geom_col(aes(x=value,y=number,group=answer,fill=answer)) + scale_fill_manual(values=c("#66c2a5", "#fc8d62"))
testPlot + geom_col(aes(x=value,y=number,group=answer,fill=answer)) + scale_fill_manual(values=c("#66c2a5", "#fc8d62")) + coord_flip()
answerCounts <- data.frame(value=" ",number=c(yesAnswers,noAnswers),answer=c("Yes","No"))
testPlot<-ggplot(answerCounts,aes(value))
testPlot + geom_col(aes(x=value,y=number,group=answer,fill=answer)) + scale_fill_manual(values=c("#66c2a5", "#fc8d62")) + coord_flip()
testPlot + geom_col(aes(x=value,y=number,group=answer,fill=answer)) + scale_fill_manual(values=c("#66c2a5", "#fc8d62")) + labs(x=NULL,y="% of active respondents") + coord_flip()
testPlot + geom_col(aes(x=value,y=number,group=answer,fill=answer)) + scale_fill_manual(values=c("#66c2a5", "#fc8d62")) + labs(x=NULL,y="% of active respondents") + guides(fill=FALSE) + coord_flip()
?round
?ylim
ggplot(answerCounts,aes(value)) + geom_col(aes(x=value,y=number,group=answer,fill=answer)) + scale_fill_manual(values=c("#66c2a5", "#fc8d62")) + labs(x=NULL,y="% of active respondents") + guides(fill=FALSE) + ylim(0,0.1) + coord_flip()
ggplot(answerCounts,aes(value)) + geom_col(aes(x=value,y=number,group=answer,fill=answer)) + scale_fill_manual(values=c("#66c2a5", "#fc8d62")) + labs(x=NULL,y="% of active respondents") + guides(fill=FALSE) + coord_flip()
ggplot(answerCounts,aes(value)) + geom_col(aes(x=value,y=number,group=answer,fill=answer)) + scale_fill_manual(values=c("#66c2a5", "#fc8d62")) + labs(x=NULL,y="% of active respondents") + guides(fill=FALSE) + ylim(0,1) + coord_flip()
ggplot(answerCounts,aes(value)) + geom_col(aes(x=value,y=number,group=answer,fill=answer)) + scale_fill_manual(values=c("#66c2a5", "#fc8d62")) + labs(x=NULL,y="% of active respondents") + guides(fill=FALSE)
?coord_equal
ggplot(answerCounts,aes(value)) + geom_col(aes(x=value,y=number,group=answer,fill=answer)) + scale_fill_manual(values=c("#66c2a5", "#fc8d62")) + labs(x=NULL,y="% of active respondents") + guides(fill=FALSE) + coord_equal(0.2) + coord_flip()
?print()
?xlab
?geom_text
answerCounts
answerCounts <- data.frame(value=" ",number=c(yesAnswers,noAnswers)/(yesAnswers+noAnswers),answer=c("Yes","No"))
answerCounts
View(mostCommonWordsYes)
max(mostCommonWordsYes$n)
max(mostCommonWordsYes$n)/max(mostCommonWordsYes$total)
?ylim
?scale_y_continuous
View(mostCommonBigramsNo)
?scale_x_continuous
?cat
?ggtitle
?position_dodge
library(tm)
library(lsa)
library(cluster)
library(dplyr)
library(slam)
library(stringr)
library(optparse)
#GRAB COMMAND LINE ARGS
option_list = list(
make_option(c("-i", "--input_file"),
type    = "character",
default = str_interp("${SHINY_ROOT}/tests/testthat/examples/lsa_training_sample.csv"),
help    = "dataset file name",
metavar = "character"
),
make_option(c("-k", "--k_clusters"),
type    = "numeric",
default = 100,
help    = "number of clusters [default= %default]",
metavar = "character"
),
make_option(c("-o", "--output_dir"),
type    = "character",
default = str_interp("${SHINY_ROOT}/tests/testthat/examples/"),
help    = "directory to which outputs are saved [default= %default]",
metavar = "character"
)
)
opt_parser = OptionParser(option_list=option_list);
opt = parse_args(opt_parser);
shiny::runApp('~/Documents/PQTool')
library(tm)
library(lsa)
library(cluster)
library(dplyr)
library(slam)
library(stringr)
library(optparse)
#GRAB COMMAND LINE ARGS
option_list = list(
make_option(c("-i", "--input_file"),
type    = "character",
default = str_interp("${SHINY_ROOT}/tests/testthat/examples/lsa_training_sample.csv"),
help    = "dataset file name",
metavar = "character"
),
make_option(c("-k", "--k_clusters"),
type    = "numeric",
default = 100,
help    = "number of clusters [default= %default]",
metavar = "character"
),
make_option(c("-o", "--output_dir"),
type    = "character",
default = str_interp("${SHINY_ROOT}/tests/testthat/examples/"),
help    = "directory to which outputs are saved [default= %default]",
metavar = "character"
)
)
opt_parser = OptionParser(option_list=option_list);
opt = parse_args(opt_parser);
savedf <- data.frame(
Document_Number = seq_along(aPQ$Question_ID),
Question_ID = aPQ$Question_ID,
Question_Text = aPQ$Question_Text,
Answer_Text = aPQ$Answer_Text,
Question_MP = questionerNames,
MP_Constituency = aPQ$MP_Constituency,
Answer_MP = answererNames,
Date = aPQ$Question_Date,
Answer_Date = aPQ$Answer_Date,
#Corrected_Date = aPQ$Corrected_Date,
Topic = klusters,
Topic_Keywords = clusterKeywordsVec[klusters],
stringsAsFactors = FALSE)
shiny::runApp('~/Documents/PQTool')
runApp('~/Documents/PQTool')
runApp('~/Documents/PQTool')
runApp('~/Documents/PQTool')
names(termsAndSumsN) <- gsub("probabl", "probability", names(termsAndSumsN))
shiny::runApp('~/Documents/PQTool')
shiny::runApp('~/Documents/PQTool')
